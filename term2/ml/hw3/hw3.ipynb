{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains missing values.\n",
      "\n",
      "0.33246753246753247% data rows have missing values in training set\n",
      "0.058823529411764705% data rows have missing values in test set\n",
      "Ratio between class \"+\" samples and class \"-\" samples in the training set is 0.6960352422907489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = ['f{0}'.format(i) for i in range(15)]\n",
    "\n",
    "dtype = {'f1': np.str }\n",
    "\n",
    "train_data = pd.read_csv('train.data',\n",
    "                         header = len(names) + 1,\n",
    "                         names = names + ['label'],\n",
    "                         skipinitialspace = True,\n",
    "                         na_values = ['?'],\n",
    "                         dtype = dtype)\n",
    "test_data = pd.read_csv('test.data',\n",
    "                        header = len(names),\n",
    "                        names = names[:len(names)],\n",
    "                        skipinitialspace = True,\n",
    "                        na_values = ['?'],\n",
    "                        dtype = dtype)\n",
    "test_labels = pd.read_csv('test.lab', header = 1, names = ['label'], skipinitialspace = True).label\n",
    "train_labels = train_data.label\n",
    "\n",
    "train_data.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "train_data.f1 = train_data.f1.astype(np.float)\n",
    "train_data.f1 = test_data.f1.astype(np.float)\n",
    "\n",
    "if train_data.isnull().any().any():\n",
    "    print('Data contains missing values.\\n')\n",
    "else:\n",
    "    print('Data does not contain missing values.\\n')\n",
    "\n",
    "missing_training_data_size = train_data[pd.isnull(train_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in training set'.format(missing_training_data_size / train_data.shape[0]))\n",
    "\n",
    "missing_test_data_size = test_data[pd.isnull(test_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in test set'.format(missing_test_data_size / test_data.shape[0]))\n",
    "\n",
    "class_one_examples_number = train_labels[train_labels == '+'].shape[0]\n",
    "class_two_examples_number = train_labels[train_labels == '-'].shape[0]\n",
    "\n",
    "print('Ratio between class \"+\" samples and class \"-\" samples in the training set is {0}'.format(class_one_examples_number / class_two_examples_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_0$ has 2 possible values 'b' and 'a'.\n",
    "\n",
    "$f_1$ has values between 1517 and 8025.\n",
    "\n",
    "$f_2$ has values between 0 and 25.085000000000001.\n",
    "\n",
    "$f_3$ has 3 possible values 'y', 'l' and 'u'.\n",
    "\n",
    "$f_4$ has 3 possible values 'p', 'g' and 'gg'.\n",
    "\n",
    "$f_5$ has 14 possible values 'cc', 'ff', 'c', 'i', 'q', 'w', 'm', 'd', 'e', 'aa', 'j', 'x', 'k' and 'r'.\n",
    "\n",
    "$f_6$ has 9 possible values 'v', 'ff', 'h', 'bb', 'j', 'z', 'o', 'n' and 'dd'.\n",
    "\n",
    "$f_7$ has values between 0 and 20.\n",
    "\n",
    "$f_8$ has 2 values 't' and 'f'.\n",
    "\n",
    "$f_9$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{10}$ has values between 0 and 20.\n",
    "\n",
    "$f_{11}$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{12}$ has 2 values 'g', 's' and 'p'\n",
    "\n",
    "$f_{13}$ has values between 0 and 0.00020000000000000001.\n",
    "\n",
    "$f_{14}$ has values between 0 and 100000.\n",
    "\n",
    "Data has 385 samples. Features $f_1, f_2, f_7, f_{10}, f_{13}, f_{14}$ are continous. Features $f_0, f_3, f_4, f_5, f_6, f_8, f_9, f_{11}, f_{12}$ are categorical. Problem has two classes. We can say that classes is more or less balanced because the ratio 0.69 is more or less close to 50 % that means that we have the half samples for class 1 and the same amount for class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "train_data_nona = DataFrameImputer().fit_transform(train_data)\n",
    "test_data_nona = DataFrameImputer().fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing values were transformed with the most frequent for object fields and mean for numeric fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for feature in names:\n",
    "    if train_data_nona[feature].dtype == np.dtype('O'): \n",
    "        train_data_nona[feature] = le.fit_transform(train_data_nona[feature])\n",
    "\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "test_labels = le.fit_transform(train_labels)\n",
    "\n",
    "categorical_features = ['f0', 'f3', 'f4', 'f5', 'f6', 'f8', 'f9', 'f11', 'f12']\n",
    "\n",
    "# enc = OneHotEncoder(categorical_features = categorical_features, sparse = False)\n",
    "# enc.fit(train_data_nona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6ff9c7f1b723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'f0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_nona\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \"\"\"\n\u001b[1;32m   1813\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[0;32m-> 1814\u001b[0;31m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[0;34m(X, transform, selected, copy)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[0msel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0msel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m     \u001b[0mnot_sel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m     \u001b[0mn_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "enc = OneHotEncoder(categorical_features = ['f0'], sparse = False)\n",
    "enc.fit_transform(train_data_nona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

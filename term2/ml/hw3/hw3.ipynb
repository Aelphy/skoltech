{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains missing values.\n",
      "\n",
      "0.33246753246753247% data rows have missing values in training set\n",
      "0.058823529411764705% data rows have missing values in test set\n",
      "Ratio between class \"+\" samples and class \"-\" samples in the training set is 0.6960352422907489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = ['f{0}'.format(i) for i in range(15)]\n",
    "\n",
    "dtype = {'f1': np.str }\n",
    "\n",
    "train_data = pd.read_csv('train.data',\n",
    "                         header = len(names) + 1,\n",
    "                         names = names + ['label'],\n",
    "                         skipinitialspace = True,\n",
    "                         na_values = ['?'],\n",
    "                         dtype = dtype)\n",
    "test_data = pd.read_csv('test.data',\n",
    "                        header = len(names),\n",
    "                        names = names[:len(names)],\n",
    "                        skipinitialspace = True,\n",
    "                        na_values = ['?'],\n",
    "                        dtype = dtype)\n",
    "test_labels = pd.read_csv('test.lab', header = 1, names = ['label'], skipinitialspace = True).label\n",
    "train_labels = train_data.label\n",
    "\n",
    "train_data.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "train_data.f1 = train_data.f1.astype(np.float)\n",
    "train_data.f1 = test_data.f1.astype(np.float)\n",
    "\n",
    "if train_data.isnull().any().any():\n",
    "    print('Data contains missing values.\\n')\n",
    "else:\n",
    "    print('Data does not contain missing values.\\n')\n",
    "\n",
    "missing_training_data_size = train_data[pd.isnull(train_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in training set'.format(missing_training_data_size / train_data.shape[0]))\n",
    "\n",
    "missing_test_data_size = test_data[pd.isnull(test_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in test set'.format(missing_test_data_size / test_data.shape[0]))\n",
    "\n",
    "class_one_examples_number = train_labels[train_labels == '+'].shape[0]\n",
    "class_two_examples_number = train_labels[train_labels == '-'].shape[0]\n",
    "\n",
    "print('Ratio between class \"+\" samples and class \"-\" samples in the training set is {0}'.format(class_one_examples_number / class_two_examples_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_0$ has 2 possible values 'b' and 'a'.\n",
    "\n",
    "$f_1$ has values between 1517 and 8025.\n",
    "\n",
    "$f_2$ has values between 0 and 25.085000000000001.\n",
    "\n",
    "$f_3$ has 3 possible values 'y', 'l' and 'u'.\n",
    "\n",
    "$f_4$ has 3 possible values 'p', 'g' and 'gg'.\n",
    "\n",
    "$f_5$ has 14 possible values 'cc', 'ff', 'c', 'i', 'q', 'w', 'm', 'd', 'e', 'aa', 'j', 'x', 'k' and 'r'.\n",
    "\n",
    "$f_6$ has 9 possible values 'v', 'ff', 'h', 'bb', 'j', 'z', 'o', 'n' and 'dd'.\n",
    "\n",
    "$f_7$ has values between 0 and 20.\n",
    "\n",
    "$f_8$ has 2 values 't' and 'f'.\n",
    "\n",
    "$f_9$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{10}$ has values between 0 and 20.\n",
    "\n",
    "$f_{11}$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{12}$ has 2 values 'g', 's' and 'p'\n",
    "\n",
    "$f_{13}$ has values between 0 and 0.00020000000000000001.\n",
    "\n",
    "$f_{14}$ has values between 0 and 100000.\n",
    "\n",
    "Data has 385 samples. Features $f_1, f_2, f_7, f_{10}, f_{13}, f_{14}$ are continous. Features $f_0, f_3, f_4, f_5, f_6, f_8, f_9, f_{11}, f_{12}$ are categorical. Problem has two classes. We can say that classes is more or less balanced because the ratio 0.69 is more or less close to 50 % that means that we have the half samples for class 1 and the same amount for class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "DataFrameImputer().fit(train_data)\n",
    "train_data_nona = DataFrameImputer().fit_transform(train_data)\n",
    "test_data_nona = DataFrameImputer().fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing values were transformed with the most frequent for object fields and mean for numeric fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "categorical_features = [0, 3, 4, 5, 6, 8, 9, 11, 12]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    train_data_nona[names[feature]] = le.fit_transform(train_data_nona[names[feature]])\n",
    "    test_data_nona[names[feature]] = le.fit_transform(test_data_nona[names[feature]])\n",
    "\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "test_labels = le.fit_transform(test_labels)\n",
    "\n",
    "enc = OneHotEncoder(categorical_features = categorical_features, sparse = False)\n",
    "enc.fit(train_data_nona)\n",
    "transformed_train = enc.transform(train_data_nona)\n",
    "transformed_test = enc.transform(test_data_nona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I have changed all the lablings for categorical data and the applied One Hot Encoding to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7717992533782007 % (+/- 0.15416044072907314)\n",
      "Accuracy: 0.8130606235869393 % (+/- 0.15164466122114262)\n",
      "Accuracy: 0.724774348458559 % (+/- 0.100326783323681)\n",
      "Accuracy: 0.8545209176788123 % (+/- 0.2746649865019716)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import cross_validation\n",
    "\n",
    "def estimate_accuracy(clf, train_data, train_labels):\n",
    "    scores = cross_validation.cross_val_score(clf, train_data, train_labels, cv = 5)\n",
    "\n",
    "    print('Accuracy: {0} % (+/- {1})'.format(scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_features = 1)\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 1)\n",
    "estimate_accuracy(clf, transformed_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy was reached when the depth of the tree was 1. But in that configuration standard deviation was very large. Also, it is interesting that  information gain works better on the given dataset. Obviously, decreasing amount of features to use reduces the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.57 s per loop\n",
      "The best score is 0.8545454545454545 (+- 0.2746649865019716) with parameters {'max_depth': 1, 'max_features': None, 'presort': True, 'criterion': 'entropy'} .\n",
      "Grid search took about 1.5666889720014296 s.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "tuned_parameters = [{'criterion': ['entropy', 'gini'],\n",
    "                     'max_features': [None, 1, 10, 20, 30, 46, 'auto', 'sqrt', 'log2'],\n",
    "                     'max_depth': [1, 10, 100, 1000],\n",
    "                     'presort' : [True, False]\n",
    "                    }]\n",
    "\n",
    "clf = grid_search.GridSearchCV(tree.DecisionTreeClassifier(), tuned_parameters, cv = 5)\n",
    "timing = %timeit -o clf.fit(transformed_train, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))\n",
    "print('Grid search took about {0} s.'.format(timing.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5717081164449586 % (+/- 0.049514617088601505)\n",
      "Accuracy: 0.6129344339870656 % (+/- 0.021633371232247595)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "X_normalized = preprocessing.normalize(transformed_train, norm = 'l2')\n",
    "clf = svm.SVC()\n",
    "estimate_accuracy(clf, X_normalized, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that normalization improves svm classification score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is 0.5896103896103896 (+- 0.00561921852408285) with parameters {'C': 0.1, 'kernel': 'rbf'} .\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [0.1, 0.2, 0.5],\n",
    "                     'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "                    },\n",
    "                    {'C': [0.1, 0.2, 0.5],\n",
    "                     'kernel': ['poly'],\n",
    "                     'degree': [1, 2, 3, 4, 5]\n",
    "                    }]\n",
    "\n",
    "clf = grid_search.GridSearchCV(svm.SVC(), tuned_parameters, cv = 5)\n",
    "clf.fit(X_normalized, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 1.65 s per loop\n",
      "The best score Decision Tree is 0.8571428571428571 (+- 0.26878092291129063) with parameters {'max_depth': 1, 'max_features': None, 'presort': True, 'criterion': 'entropy'} .\n",
      "Grid search Decision Tree took about 1.6524755480349995 s.\n",
      "\n",
      "1 loops, best of 3: 902 ms per loop\n",
      "The best score SVM is 0.5896103896103896 (+- 0.00561921852408285) with parameters {'C': 0.1, 'kernel': 'rbf'} .\n",
      "Grid search SVM took about 0.9015726610086858 s.\n",
      "\n",
      "10 loops, best of 3: 120 ms per loop\n",
      "The best score Logistic Regression is 0.7168831168831169 (+- 0.16004900824270843) with parameters {'C': 0.01, 'penalty': 'l1'} .\n",
      "Grid search Logistic Regression took about 0.12002614900120534 s.\n",
      "\n",
      "1 loops, best of 3: 920 ms per loop\n",
      "The best score KNN is 0.6779220779220779 (+- 0.14702194851204545) with parameters {'algorithm': 'ball_tree', 'p': 1, 'n_neighbors': 1} .\n",
      "Grid search KNN took about 0.9204375360277481 s.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "\n",
    "svm_tuned_parameters = [{'C': [0.1, 0.2, 0.5],\n",
    "                         'kernel': ['rbf', 'linear', 'sigmoid']\n",
    "                        },\n",
    "                        {'C': [0.1, 0.2, 0.5],\n",
    "                         'kernel': ['poly'],\n",
    "                         'degree': [1, 2, 3, 4, 5]\n",
    "                        }]\n",
    "\n",
    "dt_tuned_parameters = [{'criterion': ['entropy', 'gini'],\n",
    "                         'max_features': [None, 1, 10, 20, 30, 46, 'auto', 'sqrt', 'log2'],\n",
    "                         'max_depth': [1, 10, 100, 1000],\n",
    "                         'presort' : [True, False]\n",
    "                        }]\n",
    "\n",
    "lr_tuned_parameters = [{'penalty': ['l1', 'l2'],\n",
    "                        'C': [0.01, 0.1, 1, 0.5]\n",
    "                        }]\n",
    "\n",
    "knn_tuned_parameters = [{'n_neighbors': [1, 5, 30],\n",
    "                         'algorithm': ['ball_tree', 'kd_tree', 'brute'],\n",
    "                         'p': [1, 2, 15]\n",
    "                         }]\n",
    "\n",
    "dt_clf = tree.DecisionTreeClassifier()\n",
    "clf = grid_search.GridSearchCV(dt_clf, dt_tuned_parameters, cv = 5)\n",
    "timing = %timeit -o clf.fit(X_normalized, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score Decision Tree is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))\n",
    "print('Grid search Decision Tree took about {0} s.\\n'.format(timing.best))\n",
    "\n",
    "svm_clf = svm.SVC()\n",
    "clf = grid_search.GridSearchCV(svm_clf, svm_tuned_parameters, cv = 5)\n",
    "timing = %timeit -o clf.fit(X_normalized, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score SVM is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))\n",
    "print('Grid search SVM took about {0} s.\\n'.format(timing.best))\n",
    "\n",
    "lr_clf = linear_model.LogisticRegression()\n",
    "clf = grid_search.GridSearchCV(lr_clf, lr_tuned_parameters, cv = 5)\n",
    "timing = %timeit -o clf.fit(transformed_train, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score Logistic Regression is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))\n",
    "print('Grid search Logistic Regression took about {0} s.\\n'.format(timing.best))\n",
    "\n",
    "knn_clf = neighbors.KNeighborsClassifier()\n",
    "clf = grid_search.GridSearchCV(knn_clf, knn_tuned_parameters, cv = 5)\n",
    "timing = %timeit -o clf.fit(X_normalized, train_labels)\n",
    "params, mean, scores = clf.grid_scores_[0]\n",
    "print('The best score KNN is {1} (+- {2}) with parameters {0} .'.format(params, mean, scores.std() * 2))\n",
    "print('Grid search KNN took about {0} s.\\n'.format(timing.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_normalized_test = preprocessing.normalize(transformed_test, norm = 'l2')\n",
    "\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth = 1, criterion = 'entropy', max_features = None, presort = True)\n",
    "dt_clf.fit(X_normalized, train_labels)\n",
    "\n",
    "answers = dt_clf.predict(X_normalized_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70588235294117652"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.score(X_normalized_test, test_labels[0:272])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

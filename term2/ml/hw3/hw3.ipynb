{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data contains missing values.\n",
      "\n",
      "0.33246753246753247% data rows have missing values in training set\n",
      "0.058823529411764705% data rows have missing values in test set\n",
      "Ratio between class \"+\" samples and class \"-\" samples in the training set is 0.6960352422907489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "names = ['f{0}'.format(i) for i in range(15)]\n",
    "\n",
    "dtype = {'f1': np.str }\n",
    "\n",
    "train_data = pd.read_csv('train.data',\n",
    "                         header = len(names) + 1,\n",
    "                         names = names + ['label'],\n",
    "                         skipinitialspace = True,\n",
    "                         na_values = ['?'],\n",
    "                         dtype = dtype)\n",
    "test_data = pd.read_csv('test.data',\n",
    "                        header = len(names),\n",
    "                        names = names[:len(names)],\n",
    "                        skipinitialspace = True,\n",
    "                        na_values = ['?'],\n",
    "                        dtype = dtype)\n",
    "test_labels = pd.read_csv('test.lab', header = 1, names = ['label'], skipinitialspace = True).label\n",
    "train_labels = train_data.label\n",
    "\n",
    "train_data.drop('label', axis = 1, inplace = True)\n",
    "\n",
    "train_data.f1 = train_data.f1.astype(np.float)\n",
    "train_data.f1 = test_data.f1.astype(np.float)\n",
    "\n",
    "if train_data.isnull().any().any():\n",
    "    print('Data contains missing values.\\n')\n",
    "else:\n",
    "    print('Data does not contain missing values.\\n')\n",
    "\n",
    "missing_training_data_size = train_data[pd.isnull(train_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in training set'.format(missing_training_data_size / train_data.shape[0]))\n",
    "\n",
    "missing_test_data_size = test_data[pd.isnull(test_data).any(axis=1)].shape[0]\n",
    "\n",
    "print('{0}% data rows have missing values in test set'.format(missing_test_data_size / test_data.shape[0]))\n",
    "\n",
    "class_one_examples_number = train_labels[train_labels == '+'].shape[0]\n",
    "class_two_examples_number = train_labels[train_labels == '-'].shape[0]\n",
    "\n",
    "print('Ratio between class \"+\" samples and class \"-\" samples in the training set is {0}'.format(class_one_examples_number / class_two_examples_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f_0$ has 2 possible values 'b' and 'a'.\n",
    "\n",
    "$f_1$ has values between 1517 and 8025.\n",
    "\n",
    "$f_2$ has values between 0 and 25.085000000000001.\n",
    "\n",
    "$f_3$ has 3 possible values 'y', 'l' and 'u'.\n",
    "\n",
    "$f_4$ has 3 possible values 'p', 'g' and 'gg'.\n",
    "\n",
    "$f_5$ has 14 possible values 'cc', 'ff', 'c', 'i', 'q', 'w', 'm', 'd', 'e', 'aa', 'j', 'x', 'k' and 'r'.\n",
    "\n",
    "$f_6$ has 9 possible values 'v', 'ff', 'h', 'bb', 'j', 'z', 'o', 'n' and 'dd'.\n",
    "\n",
    "$f_7$ has values between 0 and 20.\n",
    "\n",
    "$f_8$ has 2 values 't' and 'f'.\n",
    "\n",
    "$f_9$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{10}$ has values between 0 and 20.\n",
    "\n",
    "$f_{11}$ has 2 values 't' and 'f'\n",
    "\n",
    "$f_{12}$ has 2 values 'g', 's' and 'p'\n",
    "\n",
    "$f_{13}$ has values between 0 and 0.00020000000000000001.\n",
    "\n",
    "$f_{14}$ has values between 0 and 100000.\n",
    "\n",
    "Data has 385 samples. Features $f_1, f_2, f_7, f_{10}, f_{13}, f_{14}$ are continous. Features $f_0, f_3, f_4, f_5, f_6, f_8, f_9, f_{11}, f_{12}$ are categorical. Problem has two classes. We can say that classes is more or less balanced because the ratio 0.69 is more or less close to 50 % that means that we have the half samples for class 1 and the same amount for class 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "\n",
    "train_data_nona = DataFrameImputer().fit_transform(train_data)\n",
    "test_data_nona = DataFrameImputer().fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the missing values were transformed with the most frequent for object fields and mean for numeric fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "categorical_features = [0, 3, 4, 5, 6, 8, 9, 11, 12]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    train_data_nona[names[feature]] = le.fit_transform(train_data_nona[names[feature]])\n",
    "    test_data_nona[names[feature]] = le.fit_transform(test_data_nona[names[feature]])\n",
    "\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "test_labels = le.fit_transform(train_labels)\n",
    "\n",
    "enc = OneHotEncoder(categorical_features = categorical_features, sparse = False)\n",
    "transformed_train = enc.fit_transform(train_data_nona)\n",
    "transformed_test = enc.fit_transform(test_data_nona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I have changed all the lablings for categorical data and the applied One Hot Encoding to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.774059274059274 % (+/- 0.12810621205593303)\n",
      "Accuracy: 0.8105657500394342 % (+/- 0.12210216687220216)\n",
      "Accuracy: 0.7091189512242144 % (+/- 0.1419345020803041)\n",
      "Accuracy: 0.8545209176788123 % (+/- 0.2746649865019716)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85452091767881233"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import cross_validation\n",
    "\n",
    "def estimate_accuracy(clf, train_data, train_labels):\n",
    "    scores = cross_validation.cross_val_score(clf, train_data, train_labels, cv = 5)\n",
    "\n",
    "    print('Accuracy: {0} % (+/- {1})'.format(scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "    \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_features = 1)\n",
    "estimate_accuracy(clf, transformed_train, train_labels)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 1)\n",
    "estimate_accuracy(clf, transformed_train, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy was reached when the depth of the tree was 1. But in that configuration standard deviation was very large. Also, it is interesting that  information gain works better on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
